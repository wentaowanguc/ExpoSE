# 1. History of Symbolic Execution

Symbolic execution is a technique for testing program correctness initially proposed in the 1970s. Classically, it's the process of executing a program by representing its variables as arbitrary symbols rather than concrete values. Execution of the program occurs using these symbolic inputs by extending the basic operators and semantics of the program's language to use symbols and produce symbolic formulas rather than concrete values. These symbolic formulas represent the set of the values that the variable could take and in doing so, each run of a program in symbolic execution tests many actual instances of execution. If statements, and language features that cause execution to diverge, are represented as a branch condition, a conjunction of conditions on symbols that must be satisfied. Evaluating the branch condition using a constraint solver allows you to identify whether a path is feasible and if so, the satisfied version of that constraint provides the set of concrete inputs that the path could be run under[^1].  In the trivial case, if only one path is feasible, then execution occurs down that path. In the case where both paths are feasible, then parallel execution occurs, which causes the program state to diverge. At the end of execution the path condition, the conjunction of branch conditions taken to the current point of execution, provides a unique representation of a path tested through the program and when solved using a constraint solver produces a set of inputs that when run take the same path through the program as the symbolic execution [^3][^9]. By exploring a program's paths exhaustively (or as thoroughly as possible within either a time or path count constraint) and combining symbolic execution with techniques to compare symbolic output with expected values it's possible to test a program's correctness. [^1]

For example, consider the program below which returns the sum of the absolute values of two values. There are four possible paths that can be taken through the program. The first is where neither if branches are entered, the second is where the value of `x` is less than zero, the third is where the value of `y` is less than zero, and the fourth is where both `x` and `y` is less than zero. Symbolic execution would explore each of these paths and produce concrete values for each path.

```javascript
1 function abs_sum (x, y){
2  if (x < 0)
3    x = x * -1
4  if (y < 0)
5    y = y * -1
6  return x + y
7 }
```

Historically, this technique has been impractical due to the limitations on computing resources and the capabilities of automated theorem provers[^1] however in the 2000s there was a a number of advancements in the technique by DART, EXE, and Microsoft's SAGE, made feasible due to the improvements in computer hardware and the improvement of solvers[^5][^8].

In these modern implementations, the program is run both concretely and symbolically in so called concolic execution. In concolic execution, the program is instrumented to run concretely whilst the program state is shadowed by symbolic variables allowing the concrete execution to 'drive' the symbolic execution. Unlike pure symbolic execution, concolic execution requires its initial input to be concrete, this input can be random or crafted to fit the target program[^4][^9]. As concolic execution concretely executes programs, rather than just modelling the semantics of the language you can be sure that any bugs found are actual bugs. Additionally, when a constraint cannot be solved concolic execution allows concrete values to be substituted for unsolvable elements of constraints[^6][^7].

# 2. Limitations 

## 2.1 Finding and Choosing Paths

Although in theory symbolic execution will exhaustively search through all feasible paths, as the complexity of the program under test increases the number of paths in the program increases roughly exponentially[^9]. As these symbolic execution tools are bounded by real world time constraint, paths must be chosen carefully in order to prioritise exploring 'interesting' cases in the time available.

In EXE, and other more traditional methods, paths are found by building a control flow graph and then exploring the graph using a form of breadth-first search (BFS) or depth-first search base. Neither BFS or DFS are particularly well suited for the problem, DFS is especially flawed due to its ability to get 'stuck' in a symbolically bounded loop [^5]. 

DART and SAGE, by contrast, uses a directed search strategy. Following the initial input, paths are generated by repeated negating the conditions in the path condition that was explored. Then paths are prioritised using a priority queue [^3].

In detail the algorithm for finding new test inputs is as follows, starting with an initial input *i* which has an attribute, _bound_ of 0, and a priority queue _pq_ the program executes symbolically and returns the path condition for its execution, _pc_, in the form of a sequence of predicates _c~1~ ^ c~2~ ^ ... c~n~_.  To explore alternatives to the branches that were chosen in the last execution, for _j = i.bound ... n_ where _n_ is the number of predicates in _pc_,  new inputs are generated by negating the _c~j~_ and solving the new constraint [^3][^4].  Each new input is pushed to _pq_ with a bound of _j_.  _bound_ is used to prevent path conditions being explored multiple times. The paths in the priority queue can then be prioritised using a chosen heuristic [^9]. 

## 2.2 Constraint Solving

Constraint solvers are used for two purposes in symbolic execution: determining the satisfiability of branch/path constraints and producing concrete input for satisfiable conditions. Despite continual improvements in the performance of constraint solvers, calls to solvers are typically the bottleneck is symbolic execution - fortunately there are a number of possible optimisations that can be done to reduce the burden on constraint solvers and achieve better performance [^9].

##Caching

Frequently constraints will need to be solved multiple times throughout the course of execution. Instead of calling the constraint solver multiple times for the same constraint, satisfying results can be stored in a map of constraints to satisfying results. Then, instead of directly calling the constraint solver directly, a cache lookup can be performed first to see if there is a satisfying result [^10].

This caching process can be extended to evaluate the strength of formulas. If there is a satisfying result for a stronger constraint than the one being queried then that satisfying result will be valid for the weak constraint. For instance, if the cache contains the following mapping `(x > 3 ^ y < 1) ^ x < 10 -> {x: 5, y: -214} ` then the satisfying result will be valid for the condition `x > 3 ^ y < 1`. This caching scheme can also be used to cache unsatisfiable constraints [^10].

## Removing Redundant Constraints

The majority of queries to the constraint solver in concolic execution are to determine the feasibility of a given branch. In most cases a branch's condition will not depend on all of the variables in a path constraint allowing redundant constraints to be eliminated before passing the constraint to constraint solver. Although if this technique is applied the constraint solver will only return satisfiable values for non-eliminated variables, the existing concrete values of the other variables can be used to produce a full set inputs [^9].

For instance, consider the following function.

```javascript
function unlikely_function (x, y, z){
 if (x < 0)
   x--
 if (z > 5)
   z++
 if (y < 13)
   y++
 if (y + x > 15)
   y = y * x
 return x + y + z
}
```

If the existing path constraint is (_x_ < 0) ^ (_z_ > 5) ^ (_y_ < 13) ^ (_y_ + _x_ > 15) and I'm negating the last path condition to explore a new path:   (_x_ < 0) ^ (_z_ > 5) ^ (_y_ < 13) ^ ¬(_y_ + _x_ > 15) then the _z_ > 5 constraint can be eliminated as _z_ does not influence the _y_ + _x_ > 15 branch.

# 3. Symbolic Execution for Bug Detection

Symbolic execution can be used for a variety of purposes, for instance: generating test inputs, finding infeasible paths,  finding equivalent (and therefore redundant code) but its typical application, and the focus of this project, is bug detection. 

In classical symbolic execution, as no actual code is executed bugs must be detected through the use of logical assertions that are tested by the constraint solver.  EFFIGY, described in [^1] uses the concept an input predicate and an output predicate to determine program correctness, if for all inputs which satisfy the input predicate also satisfy the output predicate then the program is said to be correct. These are implemented through the use of `ASSERT`, `ASSUME`, and `PROVE` statements.  In modern symbolic execution tools such as DART, rather than having to add additional assertions bugs are detected when runtime exceptions occur [^3].

Symbolic execution offers a number advantages over typical testing techniques. Unit and integration testing are expensive and require a large amount of effort to reach 100% coverage. In addition, they require a large amount of mock and driver code to be written, often exceeding the size of the program under test. Unit testing and integration often miss 'corner case' bugs, which are not considered either when the program is developed or when the system is tested.

Static analysis is much cheaper to run but at the cost of precision. Static analysis often produces false reports and consequently also requires a large amount of time spent to identify actual faults. Static analysis often may struggle to identify subtle bugs due to the lack of information available outside of runtime, and will typically perform worse on weakly typed languages.

Symbolic execution, like static analysis, requires no additional effort on the part of the developer and has the advantage of not producing false positives and providing a valid test case for each bug found. Symbolic execution is also effective at finding edge case bugs and can also effectively analyse the behaviour of a program when it interacts with libraries.​

[^1]: King, J. C. (1976). Symbolic execution and program testing. *Communications of the ACM*, *19*(7), 385-394.
[^2]: Godefroid, P., Levin, M. Y., & Molnar, D. A. (2008, February). Automated whitebox fuzz testing. In *NDSS* (Vol. 8, pp. 151-166).
[^3]: Godefroid, P., Klarlund, N., & Sen, K. (2005, June). DART: directed automated random testing. In *ACM Sigplan Notices* (Vol. 40, No. 6, pp. 213-223). ACM.
[^4]: Godefroid, P., Kiezun, A., & Levin, M. Y. (2008, June). Grammar-based whitebox fuzzing. In *ACM Sigplan Notices* (Vol. 43, No. 6, pp. 206-215). ACM.
[^5]: Cadar, C., Ganesh, V., Pawlowski, P. M., Dill, D. L., & Engler, D. R. (2008). EXE: automatically generating inputs of death. *ACM Transactions on Information and System Security (TISSEC)*, *12*(2), 10.
[^6]: Sen, K. (2007, November). Concolic testing. In *Proceedings of the twenty-second IEEE/ACM international conference on Automated software engineering* (pp. 571-572). ACM.
[^7]: Sen, K., Marinov, D., & Agha, G. (2005, September). CUTE: a concolic unit testing engine for C. In *ACM SIGSOFT Software Engineering Notes* (Vol. 30, No. 5, pp. 263-272). ACM.
[^8]: De Moura, L., & Bjørner, N. (2011). Satisfiability modulo theories: introduction and applications. *Communications of the ACM*, *54*(9), 69-77.
[^9]: Cadar, C., & Sen, K. (2013). Symbolic execution for software testing: three decades later. *Communications of the ACM*, *56*(2), 82-90.
[^10]: Cadar, C., Dunbar, D., & Engler, D. R. (2008, December). KLEE: Unassisted and Automatic Generation of High-Coverage Tests for Complex Systems Programs. In *OSDI* (Vol. 8, pp. 209-224).